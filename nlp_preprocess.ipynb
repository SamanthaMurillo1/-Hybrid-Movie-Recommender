{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (5.2.0)\n",
      "Requirement already satisfied: spacytextblob in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (5.1.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (1.8.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: scipy in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: spacy>=3.8.7 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacytextblob) (3.8.11)\n",
      "Requirement already satisfied: textblob>=0.18.0.post0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacytextblob) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (0.21.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from spacy>=3.8.7->spacytextblob) (68.0.0)\n",
      "Requirement already satisfied: nltk>=3.9 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from textblob>=0.18.0.post0->spacytextblob) (3.9.2)\n",
      "Requirement already satisfied: sympy in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: click in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from nltk>=3.9->textblob>=0.18.0.post0->spacytextblob) (8.1.8)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.7->spacytextblob) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.7->spacytextblob) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.8.7->spacytextblob) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.8.7->spacytextblob) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.8.7->spacytextblob) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.8.7->spacytextblob) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from jinja2->spacy>=3.8.7->spacytextblob) (3.0.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/sammurillo/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# The '!' allows you to run terminal commands inside the notebook\n",
    "# The '--user' ensures it bypasses permission issues\n",
    "!pip install -U sentence-transformers spacytextblob scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import pandas as pd\n",
    "# from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "# import ast\n",
    "# import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing spaCy...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x171355850>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Initialize NLP Tools\n",
    "print(\"Initializing spaCy...\")\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    import os\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning\n",
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv')\n",
    "df = movies.merge(credits, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list(obj):\n",
    "    return [i['name'] for i in ast.literal_eval(obj)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].apply(convert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keywords'] = df['keywords'].apply(convert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cast'] = df['cast'].apply(lambda x: [i['name'] for i in ast.literal_eval(x)[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. NLP Feature Extraction\n",
    "def process_text(text):\n",
    "    if pd.isna(text): return \"\", 0.0\n",
    "    doc = nlp(text)\n",
    "    # Get lemmas and remove noise\n",
    "    clean = \" \".join([t.lemma_.lower() for t in doc if not t.is_stop and not t.is_punct])\n",
    "    return clean, doc._.blob.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing movie tones and cleaning text...\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing movie tones and cleaning text...\")\n",
    "nlp_data = df['overview'].apply(process_text)\n",
    "df['cleaned_overview'] = [x[0] for x in nlp_data]\n",
    "df['tone_score'] = [x[1] for x in nlp_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>cleaned_overview</th>\n",
       "      <th>tone_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[Action, Adventure, Fantasy, Science Fiction]</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[culture clash, future, space war, space colon...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "      <td>19995</td>\n",
       "      <td>[Sam Worthington, Zoe Saldana, Sigourney Weaver]</td>\n",
       "      <td>[{\"credit_id\": \"52fe48009251416c750aca23\", \"de...</td>\n",
       "      <td>22nd century paraplegic marine dispatch moon p...</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                         genres  \\\n",
       "0  237000000  [Action, Adventure, Fantasy, Science Fiction]   \n",
       "\n",
       "                      homepage     id  \\\n",
       "0  http://www.avatarmovie.com/  19995   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [culture clash, future, space war, space colon...                en   \n",
       "\n",
       "  original_title                                           overview  \\\n",
       "0         Avatar  In the 22nd century, a paraplegic Marine is di...   \n",
       "\n",
       "   popularity                               production_companies  ...  \\\n",
       "0  150.437577  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...  ...   \n",
       "\n",
       "     status                      tagline   title  vote_average vote_count  \\\n",
       "0  Released  Enter the World of Pandora.  Avatar           7.2      11800   \n",
       "\n",
       "  movie_id                                              cast  \\\n",
       "0    19995  [Sam Worthington, Zoe Saldana, Sigourney Weaver]   \n",
       "\n",
       "                                                crew  \\\n",
       "0  [{\"credit_id\": \"52fe48009251416c750aca23\", \"de...   \n",
       "\n",
       "                                    cleaned_overview  tone_score  \n",
       "0  22nd century paraplegic marine dispatch moon p...    0.041667  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the search soup\n",
    "df['soup'] = df['cleaned_overview'] + \" \" + \\\n",
    "             df['genres'].apply(lambda x: \" \".join(x)) + \" \" + \\\n",
    "             df['keywords'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating movie embeddings (this powers the 'smart' search)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4383a9f731d44027b12d21c84f1c8496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Generate Semantic Vectors\n",
    "print(\"Generating movie embeddings (this powers the 'smart' search)...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(df['soup'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_test(query):\n",
    "    query_vec = model.encode([query])\n",
    "    similarity = cosine_similarity(query_vec, embeddings).flatten()\n",
    "    \n",
    "    test_df = df[['title', 'tone_score']].copy()\n",
    "    test_df['similarity'] = similarity\n",
    "    \n",
    "    # Custom Logic: If 'sad' or 'dark' is in query, prioritize lower tone_scores\n",
    "    if any(word in query.lower() for word in ['sad', 'dark', 'past']):\n",
    "        test_df['similarity'] = test_df['similarity'] * (1 - test_df['tone_score'])\n",
    "        \n",
    "    return test_df.sort_values(by='similarity', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_search(query, top_n=10):\n",
    "    # 1. Get Semantic Similarity (Using YOUR variable name 'model')\n",
    "    query_vec = model.encode([query])\n",
    "    similarity = cosine_similarity(query_vec, embeddings).flatten()\n",
    "    \n",
    "    # 2. Prepare Results DataFrame (Using YOUR variable name 'df')\n",
    "    # We create a copy to avoid modifying the original data\n",
    "    test_df = df[['title', 'tone_score', 'popularity']].copy()\n",
    "    test_df['similarity'] = similarity\n",
    "    \n",
    "    # --- STEP A: KILL THE NOISE (The Threshold) ---\n",
    "    # This ensures irrelevant movies like 'Minions' don't win just by popularity\n",
    "    test_df = test_df[test_df['similarity'] > 0.30] \n",
    "    \n",
    "    # --- STEP B: TONE & VIBE LOGIC ---\n",
    "    # We combine the \"Happy/Sad\" and \"Animated/Kids\" logic here\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    if any(word in query_lower for word in ['happy', 'fun', 'cheerful', 'animated', 'kids']):\n",
    "        # Boost movies with POSITIVE sentiment\n",
    "        test_df['similarity'] = test_df['similarity'] * (1 + test_df['tone_score'])\n",
    "    elif any(word in query_lower for word in ['sad', 'dark', 'depressing']):\n",
    "        # Boost movies with NEGATIVE sentiment\n",
    "        test_df['similarity'] = test_df['similarity'] * (1 - test_df['tone_score'])\n",
    "\n",
    "    # --- STEP C: NORMALIZATION & FINAL SCORE ---\n",
    "    # Normalize popularity to a 0-1 scale\n",
    "    test_df['pop_score'] = test_df['popularity'] / test_df['popularity'].max()\n",
    "    \n",
    "    # Final Calculation: 90% text match, 10% popularity\n",
    "    # This matches the 'Favor Text Match heavily' logic from your top function\n",
    "    test_df['final_score'] = (test_df['similarity'] * 0.9) + (test_df['pop_score'] * 0.1)\n",
    "    \n",
    "    return test_df.sort_values(by='final_score', ascending=False).head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  tone_score  \\\n",
      "4475  Aqua Teen Hunger Force Colon Movie Film for Th...    0.175000   \n",
      "4407                                The Helix... Loaded    0.000000   \n",
      "2687                         Jonah: A VeggieTales Movie    0.247222   \n",
      "3453                                       Mary Poppins    0.325902   \n",
      "1432                                            Valiant    0.025000   \n",
      "2200                                     Disaster Movie    0.015000   \n",
      "152                                     Kung Fu Panda 3    0.159028   \n",
      "1057                                      Scary Movie 2    0.011667   \n",
      "348                      Ice Age: Dawn of the Dinosaurs    0.312121   \n",
      "1863                                    Rugrats Go Wild    0.132359   \n",
      "\n",
      "      similarity  \n",
      "4475    0.566932  \n",
      "4407    0.537386  \n",
      "2687    0.530996  \n",
      "3453    0.527979  \n",
      "1432    0.524043  \n",
      "2200    0.516951  \n",
      "152     0.516328  \n",
      "1057    0.501517  \n",
      "348     0.495737  \n",
      "1863    0.491520  \n"
     ]
    }
   ],
   "source": [
    "print(semantic_search_test(\"animated movies\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smart_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sammurillo/movie recommender/nlp_preprocess.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sammurillo/movie%20recommender/nlp_preprocess.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Try the new search\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sammurillo/movie%20recommender/nlp_preprocess.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(smart_search(\u001b[39m\"\u001b[39m\u001b[39manimated\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smart_search' is not defined"
     ]
    }
   ],
   "source": [
    "# Try the new search\n",
    "print(smart_search(\"animated\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully! The .pkl contains your movie metadata and NLP vectors.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 1. Ensure you are using the dataframe that has the NLP columns\n",
    "# (title, tone_score, popularity, and soup)\n",
    "processed_movies = df[['movie_id', 'title', 'tone_score', 'popularity', 'vote_average', 'soup']]\n",
    "\n",
    "# 2. Save it as a tuple: (Dataframe, Embeddings)\n",
    "# This matches your previous 'movie_data.pkl' structure\n",
    "with open('smart_movie_models.pkl', 'wb') as file:\n",
    "    pickle.dump((processed_movies, embeddings), file)\n",
    "\n",
    "print(\"Saved successfully! The .pkl contains my movie metadata and NLP vectors.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
